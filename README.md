# Learn2Slither üêç

**A snake that learns how to behave in an environment through trial and error using Q-learning reinforcement learning**

> Train an AI agent to play Snake using Q-learning algorithm with limited vision and proper reward system.

---

## ‚ñåProject Overview

This project implements a complete Snake game with an AI agent that learns to play using **Q-learning reinforcement learning**.\
The snake learns through trial and error, gradually improving its performance over multiple training sessions.\
It serves as an introduction to **reinforcement learning fundamentals**, written from scratch without using high-level ML libraries.

üìò Educational AI project: **you'll build and train your own Q-learning model step-by-step**.

---

## ‚ñåFeatures

‚úîÔ∏è **Q-learning Algorithm**: Implements Q-table based reinforcement learning\
‚úîÔ∏è **Snake Vision**: Agent only sees 4 directions from its head (W, H, S, G, R, 0)\
‚úîÔ∏è **Proper Rewards**: Positive for green apples, negative for red apples and collisions\
‚úîÔ∏è **Model Save/Load**: Export and import trained models using pickle\
‚úîÔ∏è **Graphical Interface**: Pygame-based visualization with real-time display\
‚úîÔ∏è **Terminal Display**: Exact format as shown in subject illustrations (W, 0, G, R, H, S)\
‚úîÔ∏è **Step-by-step Mode**: Manual control for debugging and analysis\
‚úîÔ∏è **Command Line Interface**: Full CLI with all required parameters\
‚úîÔ∏è **Modular Architecture**: Separate modules for board, agent, and GUI

---

## ‚ñåFonctionnalit√©s Bonus

- ‚ñ† **Interface Graphique Am√©lior√©e** : Syst√®me de lobby, panneau de configuration, suivi des statistiques
- ‚ñ† **Tailles de Plateau Variables** : Support pour diff√©rentes dimensions (10√ó10, 15√ó15, 20√ó20, jusqu'√† 40√ó40)
- ‚ñ† **Haute Performance** : Longueur maximale atteinte de **71 cellules** apr√®s 4500 sessions
- ‚ñ† **Param√®tres Avanc√©s** : Contr√¥le de la vitesse (FPS), mode pas-√†-pas, trac√© des courbes d'apprentissage
- ‚ñ† **Statistiques D√©taill√©es** : Affichage p√©riodique des performances avec bonus atteints

> ‚ö†Ô∏è Ces fonctionnalit√©s ne sont √©valu√©es que si le programme de base fonctionne parfaitement.

---

## ‚ñåHow it works

### ‚ñ† Method Used

The model is trained using **Q-learning** with **epsilon-greedy exploration**. The objective is to maximize the **cumulative reward** by learning optimal actions for each state.

### ‚ñ† State Representation

The agent receives a 4-character string representing what it sees in each direction:
- `W` = Wall
- `H` = Snake Head  
- `S` = Snake Body
- `G` = Green Apple
- `R` = Red Apple
- `0` = Empty Space

### ‚ñ† Q-Learning Parameters

```text
Learning Rate: 0.1
Discount Factor: 0.9 (basic) / 0.95 (advanced)
Epsilon: 0.1 (exploration rate)
Epsilon Decay: 0.995
Epsilon Min: 0.01
```

### ‚ñ† Reward System

```text
Green Apple: +10
Red Apple: -10
Move without eating: -1
Game Over: -100
```

---

## ‚ñåGetting Started

### ‚ñ† Requirements

- Python 3.x
- `pygame` (graphical interface)
- `numpy` (numerical operations)
- `pickle` (model serialization)
- `tabulate` (table formatting)
- `matplotlib` (plotting, optionnel)

### ‚ñ† Installation

1. Clone the repository

```bash
git clone https://github.com/ai-dg/Learn2Slither.git
cd Learn2Slither
```

2. Install dependencies

```bash
pip install -r requirements.txt
```

---

## ‚ñåInstructions d'Utilisation

### ‚ñ† Syntaxe de Base

```bash
python3 snake.py [OPTIONS]
```

ou directement :

```bash
./snake [OPTIONS]
```

### ‚ñ† Options Disponibles

#### Options Principales

| Option | Type | D√©faut | Description |
|--------|------|--------|-------------|
| `-sessions N` | entier | 10 | Nombre de sessions d'entra√Ænement |
| `-visual [on\|off]` | choix | off | Active/d√©sactive l'affichage graphique (Pygame) |
| `-terminal [on\|off]` | choix | on | Active/d√©sactive l'affichage terminal du jeu |
| `-save PATH` | cha√Æne | - | Chemin pour sauvegarder le mod√®le entra√Æn√© (.pkl) |
| `-load PATH` | cha√Æne | - | Chemin pour charger un mod√®le pr√©-entra√Æn√© (.pkl) |
| `-dontlearn` | flag | False | D√©sactive l'apprentissage (mode √©valuation uniquement) |
| `-step-by-step` | flag | False | Active le mode pas-√†-pas (pause √† chaque mouvement) |

#### Options Bonus

| Option | Type | D√©faut | Description |
|--------|------|--------|-------------|
| `-speed N` | entier | 50 | Vitesse du jeu en FPS (frames per second) |
| `-size N` | entier | 10 | Taille du plateau (N√óN cellules, max 40) |
| `-stats` | flag | False | Affiche les statistiques toutes les 50 sessions |
| `-plot` | flag | False | Trace les courbes d'apprentissage (longueur max vs sessions) |

### ‚ñ† Exemples d'Utilisation

#### 1. Entra√Æner un mod√®le (sans affichage)

```bash
# Entra√Ænement basique avec 100 sessions
python3 snake.py -sessions 100 -visual off -save models/my_model.pkl

# Entra√Ænement avec statistiques
python3 snake.py -sessions 1000 -visual off -save models/1000sess.pkl -stats
```

#### 2. Entra√Æner avec affichage graphique

```bash
# Entra√Ænement avec visualisation
python3 snake.py -sessions 50 -visual on -speed 10

# Entra√Ænement avec visualisation et mode pas-√†-pas
python3 snake.py -sessions 10 -visual on -step-by-step -speed 5
```

#### 3. √âvaluer un mod√®le pr√©-entra√Æn√©

```bash
# Charger et √©valuer sans apprentissage
python3 snake.py -load models/1000sess.pkl -sessions 10 -dontlearn

# √âvaluation avec visualisation
python3 snake.py -load models/1000sess.pkl -sessions 5 -visual on -dontlearn -speed 10
```

#### 4. Entra√Æner avec diff√©rentes tailles de plateau

```bash
# Plateau 15√ó15
python3 snake.py -sessions 100 -size 15 -visual off -save models/15x15_100sess.pkl

# Plateau 20√ó20
python3 snake.py -sessions 200 -size 20 -visual off -save models/20x20_200sess.pkl
```

#### 5. Visualiser les courbes d'apprentissage

```bash
# Entra√Ænement avec trac√© des statistiques
python3 snake.py -sessions 500 -visual off -plot -stats -save models/500sess.pkl
```

#### 6. Mode terminal uniquement (sans GUI)

```bash
# Affichage terminal uniquement
python3 snake.py -sessions 50 -visual off -terminal on

# Sans affichage du tout (entra√Ænement rapide)
python3 snake.py -sessions 1000 -visual off -terminal off
```

### ‚ñ† R√®gles du Jeu

- **Taille du plateau** : 10√ó10 cellules par d√©faut (configurable)
- **Pommes vertes** : 2 pommes vertes apparaissent al√©atoirement
- **Pomme rouge** : 1 pomme rouge appara√Æt al√©atoirement
- **Longueur initiale** : Le serpent commence avec une longueur de 3 cellules
- **Conditions de fin** :
  - Collision avec un mur ‚Üí Game Over
  - Collision avec sa propre queue ‚Üí Game Over
  - Longueur du serpent atteint 0 ‚Üí Game Over
- **M√©caniques** :
  - Manger une pomme verte : longueur +1, nouvelle pomme verte appara√Æt
  - Manger une pomme rouge : longueur -1, nouvelle pomme rouge appara√Æt

---


---

## ‚ñåExemple de Sortie

### Entra√Ænement

```bash
$ python3 snake.py -sessions 100 -visual off -save models/test.pkl -stats

SESSION 1 - STATISTICS:
  Max length: 3 at session 1
  Total reward: -109.00
  Steps: 10
  Epsilon: 0.0999
  Learned states: 5
  Over: True

SESSION 50 - STATISTICS:
  Max length: 4 at session 45
  Total reward: -105.00
  Steps: 8
  Epsilon: 0.0775
  Learned states: 52
  Over: True

SESSION 100 - STATISTICS:
  Max length: 4 at session 87
  Total reward: -103.00
  Steps: 4
  Epsilon: 0.0905
  Learned states: 39
  Over: True

Model saved to ./models/test.pkl
```

### √âvaluation

```bash
$ python3 snake.py -load models/1000sess.pkl -sessions 5 -dontlearn -visual on

Loading model from: models/1000sess.pkl
Model loaded successfully.

Evaluation session 1/5...
Evaluation session 2/5...
Evaluation session 3/5...
Evaluation session 4/5...
Evaluation session 5/5...

Average performance: Length 7, Steps 1
```

---

## ‚ñåStructure du Projet

```
Learn2Slither/
‚îú‚îÄ‚îÄ snake.py              # Script principal (point d'entr√©e)
‚îú‚îÄ‚îÄ agent.py              # Impl√©mentation de l'agent Q-learning
‚îú‚îÄ‚îÄ game_data.py          # Gestion du plateau de jeu et logique
‚îú‚îÄ‚îÄ game_gui.py           # Interface graphique Pygame
‚îú‚îÄ‚îÄ requirements.txt      # D√©pendances Python
‚îú‚îÄ‚îÄ models/               # Mod√®les IA pr√©-entra√Æn√©s
‚îÇ   ‚îú‚îÄ‚îÄ 1sess.pkl        # Mod√®le entra√Æn√© avec 1 session
‚îÇ   ‚îú‚îÄ‚îÄ 10sess.pkl       # Mod√®le entra√Æn√© avec 10 sessions
‚îÇ   ‚îú‚îÄ‚îÄ 100sess.pkl      # Mod√®le entra√Æn√© avec 100 sessions
‚îÇ   ‚îú‚îÄ‚îÄ 1000sess.pkl     # Mod√®le entra√Æn√© avec 1000 sessions
‚îÇ   ‚îú‚îÄ‚îÄ 1500sess.pkl     # Mod√®le entra√Æn√© avec 1500 sessions
‚îÇ   ‚îú‚îÄ‚îÄ 2000sess.pkl     # Mod√®le entra√Æn√© avec 2000 sessions
‚îÇ   ‚îú‚îÄ‚îÄ 2500sess.pkl     # Mod√®le entra√Æn√© avec 2500 sessions
‚îÇ   ‚îú‚îÄ‚îÄ 3000sess.pkl     # Mod√®le entra√Æn√© avec 3000 sessions
‚îÇ   ‚îú‚îÄ‚îÄ 3500sess.pkl     # Mod√®le entra√Æn√© avec 3500 sessions
‚îÇ   ‚îú‚îÄ‚îÄ 4000sess.pkl     # Mod√®le entra√Æn√© avec 4000 sessions
‚îÇ   ‚îú‚îÄ‚îÄ 4500sess.pkl     # Mod√®le entra√Æn√© avec 4500 sessions
‚îÇ   ‚îî‚îÄ‚îÄ 5000sess.pkl     # Mod√®le entra√Æn√© avec 5000 sessions
‚îú‚îÄ‚îÄ assets/               # Ressources graphiques (sprites)
‚îú‚îÄ‚îÄ fonts/                # Polices de caract√®res
‚îî‚îÄ‚îÄ README.md            # Ce fichier
```

---

## ‚ñåR√©sultats de Performance

### ‚ñ† Statistiques d'Entra√Ænement R√©elles

Les statistiques suivantes proviennent de l'entra√Ænement r√©el du mod√®le :

| Sessions | Longueur Max | R√©compense Totale | √âtapes | Epsilon | √âtats Appris | Bonus Atteints |
|----------|--------------|-------------------|--------|---------|--------------|----------------|
| 1 | 3 | -109.00 | 10 | 0.0999 | 5 | - |
| 10 | 3 | -102.00 | 3 | 0.0990 | 14 | - |
| 100 | 4 | -103.00 | 4 | 0.0905 | 39 | - |
| 500 | 5 | -100.00 | 1 | 0.0606 | 88 | - |
| 1000 | 7 | -100.00 | 1 | 0.0368 | 114 | - |
| 1500 | 8 | -108.00 | 20 | 0.0223 | 137 | - |
| 2000 | 10 | -118.00 | 32 | 0.0135 | 167 | [10] |
| 2500 | 19 | -128.00 | 62 | 0.0100 | 201 | [10, 15] |
| 3000 | 25 | -135.00 | 69 | 0.0100 | 222 | [10, 15, 20, 25] |
| 3500 | 63 | -610.00 | 680 | 0.0100 | 262 | [10, 15, 20, 25, 30, 35] |
| 4000 | 67 | -530.00 | 664 | 0.0100 | 271 | [10, 15, 20, 25, 30, 35] |
| 4500 | 71 | -277.00 | 409 | 0.0100 | 269 | [10, 15, 20, 25, 30, 35] |
| 5000 | 65 | -556.00 | 468 | 0.0100 | 270 | [10, 15, 20, 25, 30, 35] |

### ‚ñ† Analyse des Performances

- **Progression** : Le mod√®le atteint une longueur maximale de **71 cellules** apr√®s 4500 sessions
- **Taux de r√©ussite** : Le mod√®le d√©veloppe des strat√©gies efficaces pour √©viter les collisions
- **Exploration** : L'epsilon d√©cro√Æt progressivement de 0.1 √† 0.01, favorisant l'exploitation
- **√âtats appris** : Le mod√®le d√©couvre environ **270 √©tats uniques** apr√®s 5000 sessions
- **Bonus** : Le mod√®le atteint r√©guli√®rement les longueurs de bonus (10, 15, 20, 25, 30, 35)

---

## ‚ñåD√©tails Techniques

### Architecture
Le projet suit une architecture modulaire :
- **`game_data.py`** : G√®re l'√©tat du jeu, les mouvements du serpent, le placement des pommes
- **`agent.py`** : Impl√©mente l'algorithme Q-learning et la prise de d√©cision
- **`game_gui.py`** : G√®re l'affichage visuel et l'interaction utilisateur
- **`snake.py`** : Orchestre l'entra√Ænement et l'√©valuation

### Qualit√© du Code
- Respect des standards Python PEP 8
- Design modulaire avec s√©paration claire des responsabilit√©s
- Gestion d'erreurs compl√®te
- Documentation extensive avec docstrings
- Validation des arguments en ligne de commande

### Outils de D√©veloppement

Pour v√©rifier et formater le code :

```bash
flake8 snake.py
autopep8 --in-place --aggressive --aggressive snake.py
```

---

## ‚ñåEvaluation

The project meets all mandatory requirements:
- ‚úÖ Q-learning implementation
- ‚úÖ Proper snake vision limitation
- ‚úÖ Correct reward system
- ‚úÖ Model save/load functionality
- ‚úÖ Graphical interface
- ‚úÖ Command line interface
- ‚úÖ Required model files (1, 10, 100 sessions)

Bonus features implemented:
- üéâ Enhanced visual interface
- üéâ Variable board sizes
- üéâ High performance achievements

---

## üìú License

This project was completed as part of the **42 School** curriculum.\
It is intended for **academic purposes only** and follows the evaluation requirements set by 42.

Unauthorized public sharing or direct copying for **grading purposes** is discouraged.\
If you wish to use or study this code, please ensure it complies with **your school's policies**.

